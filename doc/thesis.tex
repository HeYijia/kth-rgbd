%%
%% This is file `thesis.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% kthesis.dtx  (with options: `ex1')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from thesis.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file kthesis.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
\documentclass[a4paper,11pt]{kth-mag}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage[latin1]{inputenc}
\usepackage[swedish,english]{babel}
\usepackage{nada-ex}
\title{Building a 3D map from RGB-D sensors}
\author{Virgile H\"{o}gman}
\date{September 2011}
\blurb{Master's Thesis at CVAP\\Supervisor: Alper Aydemir\\Examiner: Stefan Carlsson}
\trita{TRITA xxx yyyy-nn}
\begin{document}
\frontmatter
\maketitle
\input{kth-abs}
\clearpage
\selectlanguage{swedish}
\begin{abstract}
  Denna fil ger ett avhandlingsskelett.
  Mer information om \LaTeX-mallen finns i
  dokumentationen till paketet.
\end{abstract}
\selectlanguage{english}
\clearpage
\tableofcontents
\mainmatter
\chapter{Introduction}

Currently, most of robotic mapping is performed using sensors that offers only a 2D cross section of the environment around them. The reason for this is ways of acquiring high quality 3D data were either very expensive or had hard constraints on the robot movements. However, recently there has been a great interest in processing data acquired using depth measuring sensors due to the availability of cheap and high performance RGB-D cameras. 

SLAM : Simultaneous Localisation and Mapping.
Visual SLAM : processing done on the camera data.  

\section{Goals}

\section{Thesis outline}

\chapter{Background}

\section{Microsoft Kinect}

\section{Features}

\subsection{SIFT}
Scale Invariant Feature Transform

\subsection{SURF}
Source Wiki.
SURF (Speeded Up Robust Feature) is a robust image detector \& descriptor, first presented by Herbert Bay et al. in 2006, that can be used in computer vision tasks like object recognition or 3D reconstruction. It is partly inspired by the SIFT descriptor. The standard version of SURF is several times faster than SIFT and claimed by its authors to be more robust against different image transformations than SIFT. SURF is based on sums of approximated 2D Haar wavelet responses and makes an efficient use of integral images.

\subsection{NARF}
Normal Aligned Radial Feature

\section{Matching}

\subsection{RANSAC}
RANdom SAmple Consensus. Iterative method.

Define the number of iterations.
For each iteration:
Pickup k samples randomly and determine a model (hypothesis). Evaluate this model by computing the error for all the points of the dataset. If enough points are valid (number of inliers), then the hypothesis is valid. Keep the best hypothesis with respect to the the mean error (lowest is best).

\subsection{ICP}
Iterative Closest Point. As any gradient descent method, the ICP is applicable when we have in advance an relatively good starting point. Otherwise, it will be trapped into a local minimum. One possibility, as used in Intel Labs, is to run RANSAC before, to determine the first guess for the ICP procedure.

\section{SLAM}

\subsection{EKF}

\subsection{Graph optimization}

g2o, HOG-Man, GraphSLAM

\section{Reconstruction and visualization of the map}

Point cloud. PCL.

\chapter{Method}

The approach: SIFT extraction in 2D, kd-tree matching in 2D/3D, RANSAC in 3D, g2o.

\section{Features}
\subsection{Features Extraction}

SIFT with SIFT Library.

\subsection{Features Matching}

KD-tree with SIFT Library.
Computes the initial matches between a couple of frames. Use the depth information.

\section{Transformation with RANSAC}

Done from the initial matches.
How to define the quality of transformation? 
Mean error, number of inliers, rate of inliers wrt initial matches.

\section{Graph optimization}
\subsection{Building the graph}

Compute estimations of the poses.

\subsection{Solving the graph}

Various methods proposed in g2o.

\subsection{Loop closures}

Define the criterion for loop closure.


\section{Reconstruction}

Point cloud with PCL. The positions of the cameras determine how each individual point cloud should be projected.

\chapter{Results}

Different datasets were used.

\section{CVAP (KTH)}

\subsection{1 room}
\subsection{2 rooms}
\subsection{4 rooms}

\section{other datasets}

\chapter{Future Works}

Performance improvements: SURF, SIFT GPU.

Quality improvements: ICP, graph optimization, combine sensors, define new criterions for loop closures.

Other approach:
Microsoft Fusion: no feature with real-time performance. Based on ICP, directly run on the point clouds from the depth data. Details of the method not published yet (patents?).

\chapter{Bibliography}

Intel labs
P. Henry, M. Krainin, E. Herbst, X. Ren, and D. Fox. RGB-D mapping:
Using depth cameras for dense 3D modeling of indoor environments.
In Proc. of the Intl. Symp. on Experimental Robotics (ISER), Delhi,
India, 2010.

g20
Rainer Kuemmerle, Giorgio Grisetti, Hauke Strasdat, Kurt Konolige, and Wolfram Burgard: g2o: A General Framework for Graph Optimization, IEEE International Conference on Robotics and Automation (ICRA), 2011

HOG-Man
G. Grisetti, R. K\"ummerle, C. Stachniss, U. Frese, and C. Hertzberg.
Hierarchical optimization on manifolds for online 2D and 3D mapping.
In Proc. of the IEEE Intl. Conf. on Robotics and Automation (ICRA),
Anchorage, AK, USA, 2010.

David G. Lowe, "Distinctive image features from scale-invariant keypoints," International Journal of Computer Vision, 60, 2 (2004), pp. 91-110.

\end{document}
\endinput
%%
%% End of file `thesis.tex'.



